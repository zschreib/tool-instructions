<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>ESM Embedding Tutorial - Tools Homepage</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "ESM Embedding Tutorial";
        var mkdocs_page_input_path = "embedding.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> Tools Homepage
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../PHIDRA/">PHIDRA</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ORION/">ORION</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="#">ESM Embedding Tutorial</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#description">Description</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#getting-started">Getting Started</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#dependencies">Dependencies</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#installation">Installation</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#generating-embeddings-of-viral-fine-tuned-models-using-contrastive-learning">Generating Embeddings of viral fine-tuned models using contrastive learning.</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#configuration">Configuration</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#visualization-embedding-output-using-umap-for-dimensionality-reduction">Visualization embedding output using UMAP for dimensionality reduction.</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#general-use-of-umap">General use of UMAP</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#advanced-umap-use-with-metadata">Advanced UMAP use with metadata.</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#using-hdbscan-to-cluster-embedding-plots">Using HDBSCAN to Cluster Embedding Plots</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#basic-hdbscan">Basic HDBSCAN</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#enhanced-hdbscan-with-umap">Enhanced HDBSCAN with UMAP</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#authors">Authors</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#acknowledgments">Acknowledgments</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../structure/">3D Structure Tutorial</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">Tools Homepage</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">ESM Embedding Tutorial</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="generating-embeddings-and-visualizion-tutorial">Generating Embeddings and Visualizion Tutorial<a class="headerlink" href="#generating-embeddings-and-visualizion-tutorial" title="Permanent link">&para;</a></h1>
<p>This tutorial provides a step-by-step guide for generating embeddings using ESM2 and visualizing them with UMAP.</p>
<h2 id="description">Description<a class="headerlink" href="#description" title="Permanent link">&para;</a></h2>
<p>This page will demonstrate how to use the ESM2 model to generate fine-tuned embeddings trained on viral proteins on the Biomix cluster. These embeddings capture important features of the sequences that can be useful for various downstream tasks in bioinformatics.
Once the embeddings are generated, the next step will be to utilize UMAP (Uniform Manifold Approximation and Projection) to reduce their dimensionality and create visualizations. UMAP is a widely used technique for visualizing high-dimensional data, allowing for better interpretation and analysis of the high-dimensional embedding data.</p>
<h2 id="getting-started">Getting Started<a class="headerlink" href="#getting-started" title="Permanent link">&para;</a></h2>
<h3 id="dependencies">Dependencies<a class="headerlink" href="#dependencies" title="Permanent link">&para;</a></h3>
<p>If you have a working environment and wish to add the basic requirements, you can manually install the following. It is highly recommended to use conda and create a prebuilt environment provided below.</p>
<ul>
<li><a href="https://github.com/facebookresearch/esm">ESM2</a> required to generate embeddings using pre-trained models.</li>
<li><a href="https://umap-learn.readthedocs.io/en/latest/">UMAP</a> required for embedding visualization.</li>
<li><a href="https://github.com/pytorch/pytorch">PyTorch</a> for tensor computation utilizing GPU.</li>
<li><a href="https://developer.nvidia.com/cuda-toolkit">CUDA-Toolkit</a> required for tools to utilize GPU. Needs to be a version compatible with your graphics card.</li>
<li><a href="https://www.python.org/downloads/">Python</a> &gt;= 3.8</li>
</ul>
<h3 id="installation">Installation<a class="headerlink" href="#installation" title="Permanent link">&para;</a></h3>
<ul>
<li>Conda setup (recommended) <a href="https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html">Help</a></li>
<li>Note: The same conda environment can be use for running embeddings and visualization with UMAP so long as all the dependencies are installed. </li>
</ul>
<pre><code>#Clone templates and test data
git clone https://github.com/zschreib/embedding-tutorial.git

cd embedding-tutorial

#Create conda environment with requirements
conda env create -f environment.yml

#Activation needed for UMAP visualization but not embedding generation if you follow the embedding template
conda activate esm-umap

</code></pre>
<h2 id="generating-embeddings-of-viral-fine-tuned-models-using-contrastive-learning">Generating Embeddings of viral fine-tuned models using contrastive learning.<a class="headerlink" href="#generating-embeddings-of-viral-fine-tuned-models-using-contrastive-learning" title="Permanent link">&para;</a></h2>
<h3 id="configuration">Configuration<a class="headerlink" href="#configuration" title="Permanent link">&para;</a></h3>
<p>If you are running the provided scripts on Biomix they are pre-configured to utilize viral fine-tuned models in the extract.py. If you wish to use the general ESM2 pre-trained models on all domains of life you need to clone the <a href="https://github.com/facebookresearch/esm">ESM2</a> repo and point the <code>embedding_template.sh</code> to that <code>extract.py</code> script along with the correct pre-trained datasets. See their documentation for more information. </p>
<pre><code>#Move to the embedding template

cd embedding_slurm_template

#Open the template with your favorite text editor and adjust the paths accordingly

#Biomix configuration needed to utilize GPU node. Adjust --mem accordingly (50GB should cover the models and your data)
#!/bin/bash
#SBATCH --job-name=test
#SBATCH --time=UNLIMITED
#SBATCH --gres=gpu:1
#SBATCH --partition=gpu2
#SBATCH --account=gpu2
#SBATCH --qos gpu
#SBATCH --mem 50GB

# Tells the node to activate your conda env before running job
source activate esm-umap

# Define path variables do not change unless you want to run your own models
EXTRACT_SCRIPT=&quot;/mnt/VEIL/tools/embeddings/models/extract.py&quot;
MODEL_PATH=&quot;/mnt/VEIL/tools/embeddings/models/esm2_t36_3B_UR50D.pt&quot;

#Path to input amino acid fasta file and output directory. List full path
INPUT_FILE=&quot;/work/user/fasta_file_location.fa&quot;
OUTPUT_DIR=&quot;/work/user/output/dir&quot;

#Run command for the embeddings to generate mean-representation of the protein
python $EXTRACT_SCRIPT $MODEL_PATH $INPUT_FILE $OUTPUT_DIR --repr_layers 36 --include mean

</code></pre>
<ul>
<li>Once configured the script can be sent to the slurm job scheduler using:</li>
</ul>
<pre><code>sbatch embedding_template.sh
</code></pre>
<ul>
<li>Logs will be found in the embedding_slurm_template directory. </li>
</ul>
<h2 id="visualization-embedding-output-using-umap-for-dimensionality-reduction">Visualization embedding output using UMAP for dimensionality reduction.<a class="headerlink" href="#visualization-embedding-output-using-umap-for-dimensionality-reduction" title="Permanent link">&para;</a></h2>
<h3 id="general-use-of-umap">General use of UMAP<a class="headerlink" href="#general-use-of-umap" title="Permanent link">&para;</a></h3>
<p>Basic introduction of how to process your embedding output.</p>
<pre><code>cd embedding-tutorial/umap_template

Usage: python umap_visualize.py &lt;input_directory&gt; &lt;output_plot_file.png&gt;

#Note: Highly recommened to read through the UMAP documentation and get an idea of what each of these input parameters do.

#Adjust according to how you want to represent your data.
umap.UMAP(n_neighbors=3, min_dist=0.5, n_components=2, metric='euclidean').fit(embeddings)
</code></pre>
<ul>
<li>To run the UMAP script against the test data provided you can enter the following: </li>
</ul>
<pre><code>python umap_visualize.py ../test_input/embeddings_data/ test_out.png
</code></pre>
<ul>
<li>Note: You may see some warnings if not on a GPU node but as long as there is a png image output they job as finished.</li>
</ul>
<h3 id="advanced-umap-use-with-metadata">Advanced UMAP use with metadata.<a class="headerlink" href="#advanced-umap-use-with-metadata" title="Permanent link">&para;</a></h3>
<p>Customize your plots with auto generated color maps or defined custom colors through metadata files.</p>
<pre><code>cd embedding-tutorial/umap_color_template

#The test_metadata.tsv will give a basic overview on how to structure a metadata file

Query_ID        signature
ENA_MN103542_MN103542_1_12796_10265_26  RDKL
ENA_PP514360_PP514360_1_8414_6123_12    RDKL
ENA_PP534163_PP534163_1_69504_71861_103 RDKF
ENA_PP579741_PP579741_1_77727_75163_114 RDKF
ENA_PP582188_PP582188_1_34616_36967_50  RDKL
ENA_PP554395_PP554395_1_25693_23567_24  ABCD

</code></pre>
<ul>
<li>Values here will either be auto assigned a color based on the 'signature' column or manually assigned by how you structure the umap_color_visualize.py file</li>
</ul>
<pre><code>#Example of how to edit the map_color_visualize.py file to assign custom colors manually 

def custom_color_manual(metadata_df, column_name):
    # Predefined color table
    color_table = {
        &quot;RDKF&quot;: '#ec4400',
        &quot;RDKL&quot;: '#8c29b1',
        &quot;RDKY&quot;: '#1b33e3',
        &quot;RDKH&quot;: '#008856',
        # Add more entries as needed
    }

#Note: ENA_PP554395_PP554395_1_25693_23567_24  ABCD and other embeddings present in your that do not have a mapping will default to gray 

#The manual and auto color generation will be saved here in the main function

metadata_df['auto_color'] = metadata_df[column_name].map(auto_colors)
metadata_df['manual_color'] = metadata_df[column_name].map(manual_colors)

#You can use these in the 

plot_umap(embeddings, embedding_ids, metadata_df, output_path)

#by going to the function and selecting the color map you want.

#Auto
def plot_umap(embeddings, embedding_ids, metadata, output_file):

    #maps your ids to color dictionary.
    id_to_color = dict(zip(metadata['Query_ID'], metadata['auto_color']))

#Manual
def plot_umap(embeddings, embedding_ids, metadata, output_file):

    #maps your ids to color dictionary.
    id_to_color = dict(zip(metadata['Query_ID'], metadata['manual_color']))

</code></pre>
<ul>
<li>Here is how you can run the example data to visualize output with color.</li>
</ul>
<pre><code>python umap_color_visualize.py ../test_input/embeddings_data test_metadata.tsv signature manual_color.png
</code></pre>
<ul>
<li>Note: You may see some warnings if not on a GPU node but as long as there is a png image output they job as finished.</li>
<li>These templates are in place to a basic understanding on how to color UMAP plots in relation to your data. Feel free to edit them however you want for future analysis.</li>
</ul>
<h2 id="using-hdbscan-to-cluster-embedding-plots">Using HDBSCAN to Cluster Embedding Plots<a class="headerlink" href="#using-hdbscan-to-cluster-embedding-plots" title="Permanent link">&para;</a></h2>
<p>An introduction to using HDBSCAN with generated embeddings on a UMAP plot.
For more information please see <a href="https://umap-learn.readthedocs.io/en/latest/clustering.html#">HDBSCAN</a> utilization with UMAP.
To learn more about what's going on behind HDBSCAN, check out <a href="https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html">How it works</a></p>
<h3 id="basic-hdbscan">Basic HDBSCAN<a class="headerlink" href="#basic-hdbscan" title="Permanent link">&para;</a></h3>
<p>This performs HDBSCAN clustering directly on your UMAP-transformed embeddings without taking into account local structure.</p>
<p>The UMAP transformation and HDBSCAN clustering happen here:</p>
<pre><code>def plot_umap_hdbscan(embeddings, embedding_ids, metadata, output_file):

    #Perform UMAP dimensionality reduction
    standard_embedding = umap.UMAP(n_neighbors=3, min_dist=0.2, n_components=2, metric='euclidean', random_state=42).fit_transform(embeddings)

    #Perform clustering with HDBSCAN
    labels = hdbscan.HDBSCAN(min_samples=2, min_cluster_size=3).fit_predict(embeddings)
    clustered = (labels &gt;= 0)

</code></pre>
<p>We can now plot the clustered and unclustered data here:</p>
<pre><code>    #Plotting the UMAP results with HDBSCAN clusters
    plt.figure(figsize=(10, 7))
    plt.scatter(
        standard_embedding[~clustered, 0],
        standard_embedding[~clustered, 1],
        color=&quot;gray&quot;,
        s=20,
        alpha=0.5,
        label=&quot;Noise&quot;,
        marker=&quot;1&quot; #tri_down for unclustered data
    )

    #Shapes applied to clustered data only (can modify to all if needed)
    unique_markers = set(markers)
    for marker in unique_markers:
        #Shape to embedding id
        marker_mask = np.array([(m == marker) and clustered[i] for i, m in enumerate(markers)])
        plt.scatter(
            standard_embedding[marker_mask, 0],
            standard_embedding[marker_mask, 1],
            c=labels[marker_mask],
            s=20,
            cmap=&quot;Spectral&quot;,
            marker=marker,
            alpha=0.8
        )
</code></pre>
<ul>
<li>Depending on the types of questions you want to answer with your data and assigned metadata, this may look different.</li>
</ul>
<p>To run a test on the provided data, try:</p>
<pre><code>python umap_HDBSCAN_basic.py ../test_input/embeddings_data test_metadata.tsv cluster_basic_with_metadata.png
</code></pre>
<h3 id="enhanced-hdbscan-with-umap">Enhanced HDBSCAN with UMAP<a class="headerlink" href="#enhanced-hdbscan-with-umap" title="Permanent link">&para;</a></h3>
<p>Important note taken from HDBSCAN documentation:</p>
<p>The next thing to be aware of is that when using UMAP for dimension reduction you will want to select different parameters than if you were using it for visualization. First of all we will want a larger n_neighbors value small values will focus more on very local structure and are more prone to producing fine grained cluster structure that may be more a result of patterns of noise in the data than actual clusters. In this case we will double it from the default 15 up to 30. Second it is beneficial to set min_dist to a very low value. Since we actually want to pack points together densely (density is what we want after all) a low value will help, as well as making cleaner separations between clusters. In this case we will simply set min_dist to be 0.</p>
<p>Notice the difference between the basic HDBSCAN and the order of operations for the enhanced version:</p>
<pre><code>def plot_umap_hdbscan(embeddings, embedding_ids, output_file):

    # Perform UMAP dimensionality reduction
    standard_embedding = umap.UMAP(n_neighbors=3, min_dist=0.2, n_components=2, metric='euclidean', random_state=42).fit_transform(embeddings)
    #HDBSCAN enhanced. Adjust according to data
    clusterable_embedding = umap.UMAP(n_neighbors=6, min_dist=0.0, n_components=2, random_state=42).fit_transform(embeddings)
    #Adjust according to data
    labels = hdbscan.HDBSCAN(min_samples=2, min_cluster_size=3).fit_predict(clusterable_embedding)
    #New cluster labels
    clustered = (labels &gt;= 0)

</code></pre>
<ul>
<li>Compare the output of basic and enhanced versions to better understand how your clusters shift depending on the parameters you use and how you implement HDBSCAN with UMAP.</li>
</ul>
<p>To run a test on the data provided you can try out:</p>
<pre><code>python umap_HDBSCAN_enhanced.py ../test_input/embeddings_data cluster_enhanced.png
</code></pre>
<ul>
<li>If you would like to save the embedding ID and cluster assigned to output you can always add this line in: </li>
</ul>
<pre><code>    plt.close()
    #End of plot

    #Labels indexed in same order as embedding_id (very simple way of saving output)
    df = pd.DataFrame({
        'Embedding_ID': embedding_ids,
        'Cluster': labels
    })

    #Write to output as a tab table
    df.to_csv('cluster_output.tsv', sep='\t', index=False)
</code></pre>
<h2 id="authors">Authors<a class="headerlink" href="#authors" title="Permanent link">&para;</a></h2>
<p>Contact info</p>
<p>zschreib@udel.edu</p>
<h2 id="acknowledgments">Acknowledgments<a class="headerlink" href="#acknowledgments" title="Permanent link">&para;</a></h2>
<p>Inspiration, code snippets, etc.
<a href="https://github.com/facebookresearch/esm">ESM2</a>, <a href="https://umap-learn.readthedocs.io/en/latest/">UMAP</a></p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../ORION/" class="btn btn-neutral float-left" title="ORION"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../structure/" class="btn btn-neutral float-right" title="3D Structure Tutorial">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../ORION/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../structure/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
