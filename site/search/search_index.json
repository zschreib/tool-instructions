{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bioinformatics Tools Guide \u00b6 A curated collection of my open-source tools, pipelines, and resources for genomics and data science. Welcome! This page serves as a central reference for my GitHub projects, including tools for protein language modeling , metagenomics , domain-architecture analysis , and 3D structure prediction and validation . Each project includes installation instructions, usage examples, and documentation.","title":"Home"},{"location":"#bioinformatics-tools-guide","text":"A curated collection of my open-source tools, pipelines, and resources for genomics and data science. Welcome! This page serves as a central reference for my GitHub projects, including tools for protein language modeling , metagenomics , domain-architecture analysis , and 3D structure prediction and validation . Each project includes installation instructions, usage examples, and documentation.","title":"Bioinformatics Tools Guide"},{"location":"ORION/","text":"ORf Interaction Ontology Network (ORION) \u00b6 ORf Interaction Ontology Network (ORION), a computational framework designed to explore patterns of protein cluster (PC) organization across genomes, contigs, or viral operational taxonomic unit (vOTU) sequences. Description \u00b6 ORION detects shared genomic features by analyzing the local arrangement of protein clusters (PCs) around each open reading frame (ORF). It maps each ORF position to its corresponding PC, then defines cluster blocks (CBs) using a sliding window of user-specified length. For example, a window size of three includes the focal PC plus its immediate neighbors; larger windows capture more distant PCs. By comparing the relative order of PCs within each window, ORION maintains consistent pattern matching even when ORFs shift due to rearrangements. Increasing the window size tightens the required cluster arrangement, revealing more highly conserved synteny across genomes. Dependencies \u00b6 orion can be ran either on a machine with a properly set up python environment or by creating a custom Conda environment if you do not wish to change your current setup (recommended). Installation \u00b6 I recommend using Mamba for faster dependency resolution; see the Mamba installation guide . If you prefer Conda , refer to the Conda installation guide . #Retrieve repo git clone https://github.com/zschreib/orion cd orion #Create environment (conda may be slow) mamba env create -f environment.yml #Activate environment mamba activate orion #OR conda activate orion Tool Check. If you recieve any errors here do not proceede until fixed. mmseqs -h prodigal -h #Make sure version matches main branch. python main.py --version Running ORION \u00b6 usage: main.py [-h] -i INPUT -p PREFIX [--min-seq-id MIN_SEQ_ID] [-cb CLUSTER_BLOCK] [-min MIN_GENOMES] [-jci JACCARD] [-t THREADS] [-f {graphml,csv}] [--version] Pipeline: preprocess FASTA and run ORION into one results folder options: -h, --help show this help message and exit -i, --input INPUT Path to input FASTA file. Nucleotide genomes/contigs. -p, --prefix PREFIX Base name for results directory (creates <prefix>_results) --min-seq-id MIN_SEQ_ID MMseqs2 min amino acid sequence identity for clustering. Default = 0.3 or 30%. -cb, --cluster-block CLUSTER_BLOCK Cluster block size for ORION. Default = 3. -min, --min-genomes MIN_GENOMES Minimum genomes for conserved cluster-block. Default = 5. -jci, --jaccard JACCARD Jaccard threshold for cluster block co-occurrence visual. Default = 0.25. -t, --threads THREADS Number of worker threads for ORION. Default = 1 -f, --format {graphml,csv} Output format for networks. Recommend csv for Cosmograph or graphml for Cytoscape. Default csv. --version Show program version and exit. Example run: ORION applied to the NCBI test dataset, which contains 48 phage genomes (16 Klebsiella, 16 Staphylococcus, and 16 Salmonella phage). python main.py -i NCBI_test_input/kleb_sal_staph_48_phage.fasta -p NCBI_test --min-seq-id 0.3 -cb 3 -min 3 -f csv Process parameters: clusters amino acid ORFs at 30% identity ( --min-seq-id 0.3 ), generates cluster blocks of size 3 ( -cb 3 ), retains blocks found in =3 genomes ( --min 3 ), saves output to a prefix-named directory ( -p ), and exports networks in CSV format ( -f csv ). To see more options use ( python main.py -h ). Results \u00b6 NCBI_test_results/ +-- NCBI_test_job_logs.txt +-- orion_output | +-- analysis_data | | +-- block_enrichment_scores.tsv | | +-- block_jaccard_scores.tsv | | +-- genome_enriched_blocks.tsv | +-- networks | +-- cluster_block_jaccard_metadata.csv | +-- cluster_block_jaccard_network.csv | +-- genome_to_cb_metadata.csv | +-- genome_to_cb_network.csv +-- preprocess_output +-- NCBI_test_cluster_blocks.tsv +-- NCBI_test_mmseqs_cluster_membership.tsv +-- NCBI_test_orf_metadata.tsv +-- NCBI_test_orfs.pep More details on each output files will be provided soon. Network Visuals \u00b6 Depending on the chosen format (-f), networks can be visualized in Cytoscape or Cosmograph. Since Cosmograph does not accept GraphML, we will use CSV files: Open Cosmograph: Go to Cosmograph . Upload files: Drag genome_to_cb_network.csv into Select data file Drag genome_to_cb_metadata.csv into Select metadata file Map columns: Set Source column ? Source Set Target column ? Target Launch the network: Click Launch to render the graph. Color nodes by syntenome: In the left panel under Node color by , choose metadata | syntenome . This will color genomes based on shared cluster block composition (syntenomes) and leave cluster block nodes gray. Highly shared blocks will draw their connected genomes toward the center. Citation \u00b6 If you found this tool useful, please cite: Schreiber, Z. D. ORION: ORf Interaction Ontology Network . GitHub. Retrieved July 29, 2025, from https://github.com/zschreib/orion/ . Authors \u00b6 Contributors names and contact info. zschreib@udel.edu License \u00b6 This project is licensed under the GNU General Public License v3.0 see the LICENSE file for details Acknowledgments \u00b6 Visuals provided by Cosmograph","title":"ORION"},{"location":"ORION/#orf-interaction-ontology-network-orion","text":"ORf Interaction Ontology Network (ORION), a computational framework designed to explore patterns of protein cluster (PC) organization across genomes, contigs, or viral operational taxonomic unit (vOTU) sequences.","title":"ORf Interaction Ontology Network (ORION)"},{"location":"ORION/#description","text":"ORION detects shared genomic features by analyzing the local arrangement of protein clusters (PCs) around each open reading frame (ORF). It maps each ORF position to its corresponding PC, then defines cluster blocks (CBs) using a sliding window of user-specified length. For example, a window size of three includes the focal PC plus its immediate neighbors; larger windows capture more distant PCs. By comparing the relative order of PCs within each window, ORION maintains consistent pattern matching even when ORFs shift due to rearrangements. Increasing the window size tightens the required cluster arrangement, revealing more highly conserved synteny across genomes.","title":"Description"},{"location":"ORION/#dependencies","text":"orion can be ran either on a machine with a properly set up python environment or by creating a custom Conda environment if you do not wish to change your current setup (recommended).","title":"Dependencies"},{"location":"ORION/#installation","text":"I recommend using Mamba for faster dependency resolution; see the Mamba installation guide . If you prefer Conda , refer to the Conda installation guide . #Retrieve repo git clone https://github.com/zschreib/orion cd orion #Create environment (conda may be slow) mamba env create -f environment.yml #Activate environment mamba activate orion #OR conda activate orion Tool Check. If you recieve any errors here do not proceede until fixed. mmseqs -h prodigal -h #Make sure version matches main branch. python main.py --version","title":"Installation"},{"location":"ORION/#running-orion","text":"usage: main.py [-h] -i INPUT -p PREFIX [--min-seq-id MIN_SEQ_ID] [-cb CLUSTER_BLOCK] [-min MIN_GENOMES] [-jci JACCARD] [-t THREADS] [-f {graphml,csv}] [--version] Pipeline: preprocess FASTA and run ORION into one results folder options: -h, --help show this help message and exit -i, --input INPUT Path to input FASTA file. Nucleotide genomes/contigs. -p, --prefix PREFIX Base name for results directory (creates <prefix>_results) --min-seq-id MIN_SEQ_ID MMseqs2 min amino acid sequence identity for clustering. Default = 0.3 or 30%. -cb, --cluster-block CLUSTER_BLOCK Cluster block size for ORION. Default = 3. -min, --min-genomes MIN_GENOMES Minimum genomes for conserved cluster-block. Default = 5. -jci, --jaccard JACCARD Jaccard threshold for cluster block co-occurrence visual. Default = 0.25. -t, --threads THREADS Number of worker threads for ORION. Default = 1 -f, --format {graphml,csv} Output format for networks. Recommend csv for Cosmograph or graphml for Cytoscape. Default csv. --version Show program version and exit. Example run: ORION applied to the NCBI test dataset, which contains 48 phage genomes (16 Klebsiella, 16 Staphylococcus, and 16 Salmonella phage). python main.py -i NCBI_test_input/kleb_sal_staph_48_phage.fasta -p NCBI_test --min-seq-id 0.3 -cb 3 -min 3 -f csv Process parameters: clusters amino acid ORFs at 30% identity ( --min-seq-id 0.3 ), generates cluster blocks of size 3 ( -cb 3 ), retains blocks found in =3 genomes ( --min 3 ), saves output to a prefix-named directory ( -p ), and exports networks in CSV format ( -f csv ). To see more options use ( python main.py -h ).","title":"Running ORION"},{"location":"ORION/#results","text":"NCBI_test_results/ +-- NCBI_test_job_logs.txt +-- orion_output | +-- analysis_data | | +-- block_enrichment_scores.tsv | | +-- block_jaccard_scores.tsv | | +-- genome_enriched_blocks.tsv | +-- networks | +-- cluster_block_jaccard_metadata.csv | +-- cluster_block_jaccard_network.csv | +-- genome_to_cb_metadata.csv | +-- genome_to_cb_network.csv +-- preprocess_output +-- NCBI_test_cluster_blocks.tsv +-- NCBI_test_mmseqs_cluster_membership.tsv +-- NCBI_test_orf_metadata.tsv +-- NCBI_test_orfs.pep More details on each output files will be provided soon.","title":"Results"},{"location":"ORION/#network-visuals","text":"Depending on the chosen format (-f), networks can be visualized in Cytoscape or Cosmograph. Since Cosmograph does not accept GraphML, we will use CSV files: Open Cosmograph: Go to Cosmograph . Upload files: Drag genome_to_cb_network.csv into Select data file Drag genome_to_cb_metadata.csv into Select metadata file Map columns: Set Source column ? Source Set Target column ? Target Launch the network: Click Launch to render the graph. Color nodes by syntenome: In the left panel under Node color by , choose metadata | syntenome . This will color genomes based on shared cluster block composition (syntenomes) and leave cluster block nodes gray. Highly shared blocks will draw their connected genomes toward the center.","title":"Network Visuals"},{"location":"ORION/#citation","text":"If you found this tool useful, please cite: Schreiber, Z. D. ORION: ORf Interaction Ontology Network . GitHub. Retrieved July 29, 2025, from https://github.com/zschreib/orion/ .","title":"Citation"},{"location":"ORION/#authors","text":"Contributors names and contact info. zschreib@udel.edu","title":"Authors"},{"location":"ORION/#license","text":"This project is licensed under the GNU General Public License v3.0 see the LICENSE file for details","title":"License"},{"location":"ORION/#acknowledgments","text":"Visuals provided by Cosmograph","title":"Acknowledgments"},{"location":"PHIDRA/","text":"PHIDRA \u00b6 P rotein H omology I dentification via D omain- R elated A rchitecture A simple way to search and validate identified Pfam domains of interest against a curated InterProScan Domain Architecture (IDA) file to check whether or not your proteins match a domain composition found in the InterPro Database. Description \u00b6 A Python-based package of scripts that performs an initial homology search using MMseqs2 to identify targeted proteins of interest in small or large datasets. Top hits are searched against the Pfam database using pfam_scan , and verified domains are checked and compared against a custom input InterProScan Domain Architecture (IDA) file relative to your target protein of interest. A recursive search is then performed using the full-length proteins with validated IDAs as the subject database and the original input as the query, with initial matches filtered out. This process captures potentially more distant proteins that may have been missed in the initial homology search but are functionally relevant. \u27a1\ufe0f Official documentation is hosted on PHIDRA . Getting started \u00b6 Dependencies \u00b6 phidra can be run either on a machine with a properly set up Python environment or by creating a custom Conda environment if you do not wish to change your current setup (recommended). MMseqs2 required for initial and recursive homology search. HMMER required for Pfam database creation and protein domain identification through pfam_scan . Python >= 3.8 Installation \u00b6 Conda setup (recommended) Help #Create environment with >= Python 3.8 conda create --name phidra python=3.8 #Activate environment conda activate phidra #Install hmmer/mmseqs2 (Required) conda install -c conda-forge -c bioconda mmseqs2 conda install bioconda::hmmer #Clone tool into working directory git clone https://github.com/zschreib/phidra cd phidra #Grabs required python packages pip install -r requirements.txt Python setup >= Python 3.8, requires MMseqs2 and HMMER to be already set up. git clone https://github.com/zschreib/phidra cd phidra pip install -r requirements.txt Tool and version check. If you receive any errors here, do not proceed until fixed. mmseqs -h hmmscan -h python phidra_run.py -v Setting up Pfam Database (Optional) \u00b6 If you already have a custom or existing Pfam-HMM formatted database you can skip this step. You can optionally include the Pfam-B database to perform a less restrictive search, which can help identify more remote or novel domain relationships that may be missed by the curated Pfam-A profiles. mkdir pfam_database cd pfam_database wget http://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.dat.gz wget http://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz gunzip -c Pfam-A.hmm.dat.gz > Pfam-A.hmm.dat gunzip -c Pfam-A.hmm.gz > Pfam-A.hmm rm Pfam-A.hmm.gz Pfam-A.hmm.dat.gz hmmpress Pfam-A.hmm Creating an InterProScan Domain Architecture (IDA) file \u00b6 1. Identify essential domains \u00b6 For DNA polymerase A, I have identified PF00476 (DNA_pol_A) as the core domain. Search domain on InterPro: https://www.ebi.ac.uk/interpro/entry/pfam/PF00476/domain_architecture/ and grab the full IDA profile. 2. Download domain architecture data in TSV format for all or selected domain combinations \u00b6 File should include (by default): * IDA ID (unique hash) * Domain combinations * Protein counts within IDA * Representative sequence * Representative length * Domain positions/coordinates 3. Sample IDA file in TSV format: \u00b6 IDA ID IDA Text Unique Proteins Representative Accession Representative Length Representative Domains 82911c7e8cf0ed5121595d5944b2a2f9a2c4f49e PF02739:IPR020046-PF01367:IPR020045-PF01612:IPR002562-PF00476:IPR001098 22766 P00582 928 PF02739{5_3_exonuc_N}:IPR020046{5-3_exonucl_a-hlix_arch_N}[9-170],PF01367{5_3_exonuc}:IPR020045{DNA_polI_H3TH}[171-272],PF01612{DNA_pol_A_exo1}:IPR002562{3'-5'_exonuclease_dom}[330-516],PF00476{DNA_pol_A}:IPR001098{DNA-dir_DNA_pol_A_palm_dom}[551-925] d4033548d92ed83469d80faa39cea59a849060a8 PF00476:IPR001098 18435 P00581 704 PF00476{DNA_pol_A}:IPR001098{DNA-dir_DNA_pol_A_palm_dom}[333-701] 16983c3a921f1409678537d9977eca4ed176e7c2 PF02739:IPR020046-PF01367:IPR020045-PF22619:IPR054690-PF00476:IPR001098 10607 Q04957 877 PF02739{5_3_exonuc_N}:IPR020046{5-3_exonucl_a-hlix_arch_N}[4-170],PF01367{5_3_exonuc}:IPR020045{DNA_polI_H3TH}[172-266],PF22619{DNA_polI_exo1}:IPR054690{DNA_polI_exonuclease}[318-457],PF00476{DNA_pol_A}:IPR001098{DNA-dir_DNA_pol_A_palm_dom}[498-875] ce54c2b3dc9b223aa1f4992353c0972accb51c74 PF02739:IPR020046-PF01367:IPR020045-PF00476:IPR001098 6038 O84500 866 PF02739{5_3_exonuc_N}:IPR020046{5-3_exonucl_a-hlix_arch_N}[3-166],PF01367{5_3_exonuc}:IPR020045{DNA_polI_H3TH}[167-259],PF00476{DNA_pol_A}:IPR001098{DNA-dir_DNA_pol_A_palm_dom}[495-865] f54dc0def957e931720f1460942192debd6092ca PF01612:IPR002562-PF00476:IPR001098 4576 Q05254 595 PF01612{DNA_pol_A_exo1}:IPR002562{3'-5'_exonuclease_dom}[19-210],PF00476{DNA_pol_A}:IPR001098{DNA-dir_DNA_pol_A_palm_dom}[243-587] 4. Analyze architectures \u00b6 Core domain (PF00476) commonly associates with: * PF02739 (5' exonuclease N-terminal) * PF01367 (5' exonuclease) * PF01612 (DNA polymerase A exonuclease) 5. Use for validation \u00b6 Compare unknown or known sequence hits to the subject database against known IDA profiles. Explore domain organization and composition. Domain architectures help validate protein predictions by ensuring essential functional domains are present, and they also provide structured, functionally meaningful features that can be leveraged as high-quality inputs for machine-learning models to improve training and downstream classification. Running the tool \u00b6 usage: phidra_run.py [-h] [-v] -i INPUT_FASTA -db SUBJECT_DB -pfam PFAM_HMM_DB -ida IDA_FILE -f FUNCTION -o OUTPUT_DIR [-t THREADS] [-e EVALUE] Identifies homologous proteins and associated Pfam domains from input protein sequences, while comparing against InterPro Domain Architectures to analyze domain-level similarities and functional relationships. Help: -h, --help Show this help message and exit -v, --version Show program version and exit Required arguments: -i INPUT_FASTA, --input_fasta INPUT_FASTA Query FASTA for mmseqs search (default: None) -db SUBJECT_DB, --subject_db SUBJECT_DB Subject FASTA for mmseqs createdb (default: None) -pfam PFAM_HMM_DB, --pfam_hmm_db PFAM_HMM_DB Pfam HMM format database path (default: None) -ida IDA_FILE, --ida_file IDA_FILE IDA TSV file (default: None) -f FUNCTION, --function FUNCTION User label for this run (default: None) -o OUTPUT_DIR, --output_dir OUTPUT_DIR Base output directory (default: None) Optional arguments: -t THREADS, --threads THREADS Threads for tools supporting -cpu/--threads (default: 1) -e EVALUE, --evalue EVALUE E-value threshold for mmseqs easy-search (e.g., 1E-3, 1e-5) (default: 1E-3) Example run using the provided examples directory: python phidra_run.py -i examples/query/polA_test.fa -db examples/subject/pola_16_k12_ref.fa -pfam [pfam_DB_location] -ida examples/IDA/polA_IDA_list.tsv -f examples/output -t 5 -e 1E-3 Results output summary \u00b6 output/ \u251c\u2500\u2500 final_results/ \u2502 \u251c\u2500\u2500 pfam_coverage_report.tsv # Summary of Pfam domain coverage across all search hits \u2502 \u251c\u2500\u2500 summary.tsv # Summary table combining counts for each iteration \u2502 \u251c\u2500\u2500 unvalidated_ida_pfams/ # Pfam domains found but not validated by iterative domain architecture (IDA) \u2502 \u2502 \u251c\u2500\u2500 domains.fa # FASTA of individual Pfam domain hits \u2502 \u2502 \u251c\u2500\u2500 full_proteins.fa # Full-length proteins containing those domains \u2502 \u2502 \u2514\u2500\u2500 pfam_unvalidated_merged_report.tsv # Merged table of unvalidated domain results \u2502 \u2514\u2500\u2500 validated_ida_pfams/ # Pfam domains validated by IDA recursion \u2502 \u251c\u2500\u2500 domains.fa # FASTA of validated Pfam domain hits \u2502 \u251c\u2500\u2500 full_proteins.fa # Full-length proteins containing validated domains \u2502 \u2514\u2500\u2500 pfam_validated_merged_report.tsv # Merged table of validated domain results \u2502 \u251c\u2500\u2500 mmseqs/ \u2502 \u251c\u2500\u2500 initial/ # First-pass MMseqs2 search output \u2502 \u2502 \u251c\u2500\u2500 bits.tsv # Top hit table by best bitscore \u2502 \u2502 \u251c\u2500\u2500 hits.fa # FASTA of sequences with best e-value \u2502 \u2502 \u251c\u2500\u2500 hits.tsv # Top hit table by best e-value \u2502 \u2502 \u2514\u2500\u2500 res.m8 # MMseqs2 table output (m8 format) for all significant initial hits \u2502 \u2514\u2500\u2500 recursive/ # Secondary MMseqs2 search using hits as queries \u2502 \u2514\u2500\u2500 res.m8 # MMseqs2 table output (m8 format) for all significant recursive hits \u2502 # No recursive hits so tophit/FASTA not created \u2514\u2500\u2500 pfam/ \u251c\u2500\u2500 initial/ # Initial Pfam HMMER domain search results \u2502 \u251c\u2500\u2500 pfam_coverage_report.tsv # Coverage summary of initial Pfam search \u2502 \u251c\u2500\u2500 unvalidated_ida_report/ # Domains not validated by user IDA but hit Pfam domain \u2502 \u2502 \u251c\u2500\u2500 domains.fa # FASTA of unvalidated Pfam domain hits \u2502 \u2502 \u251c\u2500\u2500 full_proteins.fa # Full-length proteins for unvalidated hits \u2502 \u2502 \u2514\u2500\u2500 pfam_unvalidated_report.tsv # Tabular report of unvalidated domain results \u2502 \u2514\u2500\u2500 validated_ida_report/ # Domains validated by IDA \u2502 \u251c\u2500\u2500 domains.fa # FASTA of validated Pfam domain hits \u2502 \u251c\u2500\u2500 full_proteins.fa # Full-length proteins for validated hits \u2502 \u2514\u2500\u2500 pfam_validated_report.tsv # Tabular report of validated domain results \u2514\u2500\u2500 recursive/ # Results from recursive Pfam search (empty) # No recursive hits so pfam files not created The named output directory contains the complete output of the phidra pipeline. Includes homology search results, IDA-validated and unvalidated Pfam domain calls with both sequence-level and domain-level FASTA files, and comprehensive summary tables. A detailed description of each file is provided above to help navigate and interpret the results. Looking for Version 1? \u00b6 Browse the stable v1.x branch Or check the v1.0.0 release Citation \u00b6 If you found this tool useful, please cite: Schreiber, Z. D. PHIDRA: Protein Homology Identification via Domain-Related Architecture . GitHub. Retrieved Sept 27, 2025, from https://github.com/zschreib/phidra/ . Authors \u00b6 Contributor\u2019s name and contact info zschreib.dev@gmail.com License \u00b6 This project is licensed under the GNU General Public License v3.0 see the LICENSE file for more details. Acknowledgments \u00b6 Inspiration, code snippets, etc. * MMseqs2 * InterPro * pfam_scan","title":"PHIDRA"},{"location":"PHIDRA/#phidra","text":"P rotein H omology I dentification via D omain- R elated A rchitecture A simple way to search and validate identified Pfam domains of interest against a curated InterProScan Domain Architecture (IDA) file to check whether or not your proteins match a domain composition found in the InterPro Database.","title":"PHIDRA"},{"location":"PHIDRA/#description","text":"A Python-based package of scripts that performs an initial homology search using MMseqs2 to identify targeted proteins of interest in small or large datasets. Top hits are searched against the Pfam database using pfam_scan , and verified domains are checked and compared against a custom input InterProScan Domain Architecture (IDA) file relative to your target protein of interest. A recursive search is then performed using the full-length proteins with validated IDAs as the subject database and the original input as the query, with initial matches filtered out. This process captures potentially more distant proteins that may have been missed in the initial homology search but are functionally relevant. \u27a1\ufe0f Official documentation is hosted on PHIDRA .","title":"Description"},{"location":"PHIDRA/#getting-started","text":"","title":"Getting started"},{"location":"PHIDRA/#dependencies","text":"phidra can be run either on a machine with a properly set up Python environment or by creating a custom Conda environment if you do not wish to change your current setup (recommended). MMseqs2 required for initial and recursive homology search. HMMER required for Pfam database creation and protein domain identification through pfam_scan . Python >= 3.8","title":"Dependencies"},{"location":"PHIDRA/#installation","text":"Conda setup (recommended) Help #Create environment with >= Python 3.8 conda create --name phidra python=3.8 #Activate environment conda activate phidra #Install hmmer/mmseqs2 (Required) conda install -c conda-forge -c bioconda mmseqs2 conda install bioconda::hmmer #Clone tool into working directory git clone https://github.com/zschreib/phidra cd phidra #Grabs required python packages pip install -r requirements.txt Python setup >= Python 3.8, requires MMseqs2 and HMMER to be already set up. git clone https://github.com/zschreib/phidra cd phidra pip install -r requirements.txt Tool and version check. If you receive any errors here, do not proceed until fixed. mmseqs -h hmmscan -h python phidra_run.py -v","title":"Installation"},{"location":"PHIDRA/#setting-up-pfam-database-optional","text":"If you already have a custom or existing Pfam-HMM formatted database you can skip this step. You can optionally include the Pfam-B database to perform a less restrictive search, which can help identify more remote or novel domain relationships that may be missed by the curated Pfam-A profiles. mkdir pfam_database cd pfam_database wget http://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.dat.gz wget http://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz gunzip -c Pfam-A.hmm.dat.gz > Pfam-A.hmm.dat gunzip -c Pfam-A.hmm.gz > Pfam-A.hmm rm Pfam-A.hmm.gz Pfam-A.hmm.dat.gz hmmpress Pfam-A.hmm","title":"Setting up Pfam Database (Optional)"},{"location":"PHIDRA/#creating-an-interproscan-domain-architecture-ida-file","text":"","title":"Creating an InterProScan Domain Architecture (IDA) file"},{"location":"PHIDRA/#1-identify-essential-domains","text":"For DNA polymerase A, I have identified PF00476 (DNA_pol_A) as the core domain. Search domain on InterPro: https://www.ebi.ac.uk/interpro/entry/pfam/PF00476/domain_architecture/ and grab the full IDA profile.","title":"1. Identify essential domains"},{"location":"PHIDRA/#2-download-domain-architecture-data-in-tsv-format-for-all-or-selected-domain-combinations","text":"File should include (by default): * IDA ID (unique hash) * Domain combinations * Protein counts within IDA * Representative sequence * Representative length * Domain positions/coordinates","title":"2. Download domain architecture data in TSV format for all or selected domain combinations"},{"location":"PHIDRA/#3-sample-ida-file-in-tsv-format","text":"IDA ID IDA Text Unique Proteins Representative Accession Representative Length Representative Domains 82911c7e8cf0ed5121595d5944b2a2f9a2c4f49e PF02739:IPR020046-PF01367:IPR020045-PF01612:IPR002562-PF00476:IPR001098 22766 P00582 928 PF02739{5_3_exonuc_N}:IPR020046{5-3_exonucl_a-hlix_arch_N}[9-170],PF01367{5_3_exonuc}:IPR020045{DNA_polI_H3TH}[171-272],PF01612{DNA_pol_A_exo1}:IPR002562{3'-5'_exonuclease_dom}[330-516],PF00476{DNA_pol_A}:IPR001098{DNA-dir_DNA_pol_A_palm_dom}[551-925] d4033548d92ed83469d80faa39cea59a849060a8 PF00476:IPR001098 18435 P00581 704 PF00476{DNA_pol_A}:IPR001098{DNA-dir_DNA_pol_A_palm_dom}[333-701] 16983c3a921f1409678537d9977eca4ed176e7c2 PF02739:IPR020046-PF01367:IPR020045-PF22619:IPR054690-PF00476:IPR001098 10607 Q04957 877 PF02739{5_3_exonuc_N}:IPR020046{5-3_exonucl_a-hlix_arch_N}[4-170],PF01367{5_3_exonuc}:IPR020045{DNA_polI_H3TH}[172-266],PF22619{DNA_polI_exo1}:IPR054690{DNA_polI_exonuclease}[318-457],PF00476{DNA_pol_A}:IPR001098{DNA-dir_DNA_pol_A_palm_dom}[498-875] ce54c2b3dc9b223aa1f4992353c0972accb51c74 PF02739:IPR020046-PF01367:IPR020045-PF00476:IPR001098 6038 O84500 866 PF02739{5_3_exonuc_N}:IPR020046{5-3_exonucl_a-hlix_arch_N}[3-166],PF01367{5_3_exonuc}:IPR020045{DNA_polI_H3TH}[167-259],PF00476{DNA_pol_A}:IPR001098{DNA-dir_DNA_pol_A_palm_dom}[495-865] f54dc0def957e931720f1460942192debd6092ca PF01612:IPR002562-PF00476:IPR001098 4576 Q05254 595 PF01612{DNA_pol_A_exo1}:IPR002562{3'-5'_exonuclease_dom}[19-210],PF00476{DNA_pol_A}:IPR001098{DNA-dir_DNA_pol_A_palm_dom}[243-587]","title":"3. Sample IDA file in TSV format:"},{"location":"PHIDRA/#4-analyze-architectures","text":"Core domain (PF00476) commonly associates with: * PF02739 (5' exonuclease N-terminal) * PF01367 (5' exonuclease) * PF01612 (DNA polymerase A exonuclease)","title":"4. Analyze architectures"},{"location":"PHIDRA/#5-use-for-validation","text":"Compare unknown or known sequence hits to the subject database against known IDA profiles. Explore domain organization and composition. Domain architectures help validate protein predictions by ensuring essential functional domains are present, and they also provide structured, functionally meaningful features that can be leveraged as high-quality inputs for machine-learning models to improve training and downstream classification.","title":"5. Use for validation"},{"location":"PHIDRA/#running-the-tool","text":"usage: phidra_run.py [-h] [-v] -i INPUT_FASTA -db SUBJECT_DB -pfam PFAM_HMM_DB -ida IDA_FILE -f FUNCTION -o OUTPUT_DIR [-t THREADS] [-e EVALUE] Identifies homologous proteins and associated Pfam domains from input protein sequences, while comparing against InterPro Domain Architectures to analyze domain-level similarities and functional relationships. Help: -h, --help Show this help message and exit -v, --version Show program version and exit Required arguments: -i INPUT_FASTA, --input_fasta INPUT_FASTA Query FASTA for mmseqs search (default: None) -db SUBJECT_DB, --subject_db SUBJECT_DB Subject FASTA for mmseqs createdb (default: None) -pfam PFAM_HMM_DB, --pfam_hmm_db PFAM_HMM_DB Pfam HMM format database path (default: None) -ida IDA_FILE, --ida_file IDA_FILE IDA TSV file (default: None) -f FUNCTION, --function FUNCTION User label for this run (default: None) -o OUTPUT_DIR, --output_dir OUTPUT_DIR Base output directory (default: None) Optional arguments: -t THREADS, --threads THREADS Threads for tools supporting -cpu/--threads (default: 1) -e EVALUE, --evalue EVALUE E-value threshold for mmseqs easy-search (e.g., 1E-3, 1e-5) (default: 1E-3) Example run using the provided examples directory: python phidra_run.py -i examples/query/polA_test.fa -db examples/subject/pola_16_k12_ref.fa -pfam [pfam_DB_location] -ida examples/IDA/polA_IDA_list.tsv -f examples/output -t 5 -e 1E-3","title":"Running the tool"},{"location":"PHIDRA/#results-output-summary","text":"output/ \u251c\u2500\u2500 final_results/ \u2502 \u251c\u2500\u2500 pfam_coverage_report.tsv # Summary of Pfam domain coverage across all search hits \u2502 \u251c\u2500\u2500 summary.tsv # Summary table combining counts for each iteration \u2502 \u251c\u2500\u2500 unvalidated_ida_pfams/ # Pfam domains found but not validated by iterative domain architecture (IDA) \u2502 \u2502 \u251c\u2500\u2500 domains.fa # FASTA of individual Pfam domain hits \u2502 \u2502 \u251c\u2500\u2500 full_proteins.fa # Full-length proteins containing those domains \u2502 \u2502 \u2514\u2500\u2500 pfam_unvalidated_merged_report.tsv # Merged table of unvalidated domain results \u2502 \u2514\u2500\u2500 validated_ida_pfams/ # Pfam domains validated by IDA recursion \u2502 \u251c\u2500\u2500 domains.fa # FASTA of validated Pfam domain hits \u2502 \u251c\u2500\u2500 full_proteins.fa # Full-length proteins containing validated domains \u2502 \u2514\u2500\u2500 pfam_validated_merged_report.tsv # Merged table of validated domain results \u2502 \u251c\u2500\u2500 mmseqs/ \u2502 \u251c\u2500\u2500 initial/ # First-pass MMseqs2 search output \u2502 \u2502 \u251c\u2500\u2500 bits.tsv # Top hit table by best bitscore \u2502 \u2502 \u251c\u2500\u2500 hits.fa # FASTA of sequences with best e-value \u2502 \u2502 \u251c\u2500\u2500 hits.tsv # Top hit table by best e-value \u2502 \u2502 \u2514\u2500\u2500 res.m8 # MMseqs2 table output (m8 format) for all significant initial hits \u2502 \u2514\u2500\u2500 recursive/ # Secondary MMseqs2 search using hits as queries \u2502 \u2514\u2500\u2500 res.m8 # MMseqs2 table output (m8 format) for all significant recursive hits \u2502 # No recursive hits so tophit/FASTA not created \u2514\u2500\u2500 pfam/ \u251c\u2500\u2500 initial/ # Initial Pfam HMMER domain search results \u2502 \u251c\u2500\u2500 pfam_coverage_report.tsv # Coverage summary of initial Pfam search \u2502 \u251c\u2500\u2500 unvalidated_ida_report/ # Domains not validated by user IDA but hit Pfam domain \u2502 \u2502 \u251c\u2500\u2500 domains.fa # FASTA of unvalidated Pfam domain hits \u2502 \u2502 \u251c\u2500\u2500 full_proteins.fa # Full-length proteins for unvalidated hits \u2502 \u2502 \u2514\u2500\u2500 pfam_unvalidated_report.tsv # Tabular report of unvalidated domain results \u2502 \u2514\u2500\u2500 validated_ida_report/ # Domains validated by IDA \u2502 \u251c\u2500\u2500 domains.fa # FASTA of validated Pfam domain hits \u2502 \u251c\u2500\u2500 full_proteins.fa # Full-length proteins for validated hits \u2502 \u2514\u2500\u2500 pfam_validated_report.tsv # Tabular report of validated domain results \u2514\u2500\u2500 recursive/ # Results from recursive Pfam search (empty) # No recursive hits so pfam files not created The named output directory contains the complete output of the phidra pipeline. Includes homology search results, IDA-validated and unvalidated Pfam domain calls with both sequence-level and domain-level FASTA files, and comprehensive summary tables. A detailed description of each file is provided above to help navigate and interpret the results.","title":"Results output summary"},{"location":"PHIDRA/#looking-for-version-1","text":"Browse the stable v1.x branch Or check the v1.0.0 release","title":"Looking for Version 1?"},{"location":"PHIDRA/#citation","text":"If you found this tool useful, please cite: Schreiber, Z. D. PHIDRA: Protein Homology Identification via Domain-Related Architecture . GitHub. Retrieved Sept 27, 2025, from https://github.com/zschreib/phidra/ .","title":"Citation"},{"location":"PHIDRA/#authors","text":"Contributor\u2019s name and contact info zschreib.dev@gmail.com","title":"Authors"},{"location":"PHIDRA/#license","text":"This project is licensed under the GNU General Public License v3.0 see the LICENSE file for more details.","title":"License"},{"location":"PHIDRA/#acknowledgments","text":"Inspiration, code snippets, etc. * MMseqs2 * InterPro * pfam_scan","title":"Acknowledgments"},{"location":"embedding/","text":"Generating Embeddings and Visualizion Tutorial \u00b6 This tutorial provides a step-by-step guide for generating embeddings using ESM2 and visualizing them with UMAP. Description \u00b6 This page will demonstrate how to use the ESM2 model to generate fine-tuned embeddings trained on viral proteins on the Biomix cluster. These embeddings capture important features of the sequences that can be useful for various downstream tasks in bioinformatics. Once the embeddings are generated, the next step will be to utilize UMAP (Uniform Manifold Approximation and Projection) to reduce their dimensionality and create visualizations. UMAP is a widely used technique for visualizing high-dimensional data, allowing for better interpretation and analysis of the high-dimensional embedding data. Getting Started \u00b6 Dependencies \u00b6 If you have a working environment and wish to add the basic requirements, you can manually install the following. It is highly recommended to use conda and create a prebuilt environment provided below. ESM2 required to generate embeddings using pre-trained models. UMAP required for embedding visualization. PyTorch for tensor computation utilizing GPU. CUDA-Toolkit required for tools to utilize GPU. Needs to be a version compatible with your graphics card. Python >= 3.8 Installation \u00b6 Conda setup (recommended) Help Note: The same conda environment can be use for running embeddings and visualization with UMAP so long as all the dependencies are installed. #Clone templates and test data git clone https://github.com/zschreib/embedding-tutorial.git cd embedding-tutorial #Create conda environment with requirements conda env create -f environment.yml #Activation needed for UMAP visualization but not embedding generation if you follow the embedding template conda activate esm-umap Generating Embeddings of viral fine-tuned models using contrastive learning. \u00b6 Configuration \u00b6 If you are running the provided scripts on Biomix they are pre-configured to utilize viral fine-tuned models in the extract.py. If you wish to use the general ESM2 pre-trained models on all domains of life you need to clone the ESM2 repo and point the embedding_template.sh to that extract.py script along with the correct pre-trained datasets. See their documentation for more information. #Move to the embedding template cd embedding_slurm_template #Open the template with your favorite text editor and adjust the paths accordingly #Biomix configuration needed to utilize GPU node. Adjust --mem accordingly (50GB should cover the models and your data) #!/bin/bash #SBATCH --job-name=test #SBATCH --time=UNLIMITED #SBATCH --gres=gpu:1 #SBATCH --partition=gpu2 #SBATCH --account=gpu2 #SBATCH --qos gpu #SBATCH --mem 50GB # Tells the node to activate your conda env before running job source activate esm-umap # Define path variables do not change unless you want to run your own models EXTRACT_SCRIPT=\"/mnt/VEIL/tools/embeddings/models/extract.py\" MODEL_PATH=\"/mnt/VEIL/tools/embeddings/models/esm2_t36_3B_UR50D.pt\" #Path to input amino acid fasta file and output directory. List full path INPUT_FILE=\"/work/user/fasta_file_location.fa\" OUTPUT_DIR=\"/work/user/output/dir\" #Run command for the embeddings to generate mean-representation of the protein python $EXTRACT_SCRIPT $MODEL_PATH $INPUT_FILE $OUTPUT_DIR --repr_layers 36 --include mean Once configured the script can be sent to the slurm job scheduler using: sbatch embedding_template.sh Logs will be found in the embedding_slurm_template directory. Visualization embedding output using UMAP for dimensionality reduction. \u00b6 General use of UMAP \u00b6 Basic introduction of how to process your embedding output. cd embedding-tutorial/umap_template Usage: python umap_visualize.py <input_directory> <output_plot_file.png> #Note: Highly recommened to read through the UMAP documentation and get an idea of what each of these input parameters do. #Adjust according to how you want to represent your data. umap.UMAP(n_neighbors=3, min_dist=0.5, n_components=2, metric='euclidean').fit(embeddings) To run the UMAP script against the test data provided you can enter the following: python umap_visualize.py ../test_input/embeddings_data/ test_out.png Note: You may see some warnings if not on a GPU node but as long as there is a png image output they job as finished. Advanced UMAP use with metadata. \u00b6 Customize your plots with auto generated color maps or defined custom colors through metadata files. cd embedding-tutorial/umap_color_template #The test_metadata.tsv will give a basic overview on how to structure a metadata file Query_ID signature ENA_MN103542_MN103542_1_12796_10265_26 RDKL ENA_PP514360_PP514360_1_8414_6123_12 RDKL ENA_PP534163_PP534163_1_69504_71861_103 RDKF ENA_PP579741_PP579741_1_77727_75163_114 RDKF ENA_PP582188_PP582188_1_34616_36967_50 RDKL ENA_PP554395_PP554395_1_25693_23567_24 ABCD Values here will either be auto assigned a color based on the 'signature' column or manually assigned by how you structure the umap_color_visualize.py file #Example of how to edit the map_color_visualize.py file to assign custom colors manually def custom_color_manual(metadata_df, column_name): # Predefined color table color_table = { \"RDKF\": '#ec4400', \"RDKL\": '#8c29b1', \"RDKY\": '#1b33e3', \"RDKH\": '#008856', # Add more entries as needed } #Note: ENA_PP554395_PP554395_1_25693_23567_24 ABCD and other embeddings present in your that do not have a mapping will default to gray #The manual and auto color generation will be saved here in the main function metadata_df['auto_color'] = metadata_df[column_name].map(auto_colors) metadata_df['manual_color'] = metadata_df[column_name].map(manual_colors) #You can use these in the plot_umap(embeddings, embedding_ids, metadata_df, output_path) #by going to the function and selecting the color map you want. #Auto def plot_umap(embeddings, embedding_ids, metadata, output_file): #maps your ids to color dictionary. id_to_color = dict(zip(metadata['Query_ID'], metadata['auto_color'])) #Manual def plot_umap(embeddings, embedding_ids, metadata, output_file): #maps your ids to color dictionary. id_to_color = dict(zip(metadata['Query_ID'], metadata['manual_color'])) Here is how you can run the example data to visualize output with color. python umap_color_visualize.py ../test_input/embeddings_data test_metadata.tsv signature manual_color.png Note: You may see some warnings if not on a GPU node but as long as there is a png image output they job as finished. These templates are in place to a basic understanding on how to color UMAP plots in relation to your data. Feel free to edit them however you want for future analysis. Using HDBSCAN to Cluster Embedding Plots \u00b6 An introduction to using HDBSCAN with generated embeddings on a UMAP plot. For more information please see HDBSCAN utilization with UMAP. To learn more about what's going on behind HDBSCAN, check out How it works Basic HDBSCAN \u00b6 This performs HDBSCAN clustering directly on your UMAP-transformed embeddings without taking into account local structure. The UMAP transformation and HDBSCAN clustering happen here: def plot_umap_hdbscan(embeddings, embedding_ids, metadata, output_file): #Perform UMAP dimensionality reduction standard_embedding = umap.UMAP(n_neighbors=3, min_dist=0.2, n_components=2, metric='euclidean', random_state=42).fit_transform(embeddings) #Perform clustering with HDBSCAN labels = hdbscan.HDBSCAN(min_samples=2, min_cluster_size=3).fit_predict(embeddings) clustered = (labels >= 0) We can now plot the clustered and unclustered data here: #Plotting the UMAP results with HDBSCAN clusters plt.figure(figsize=(10, 7)) plt.scatter( standard_embedding[~clustered, 0], standard_embedding[~clustered, 1], color=\"gray\", s=20, alpha=0.5, label=\"Noise\", marker=\"1\" #tri_down for unclustered data ) #Shapes applied to clustered data only (can modify to all if needed) unique_markers = set(markers) for marker in unique_markers: #Shape to embedding id marker_mask = np.array([(m == marker) and clustered[i] for i, m in enumerate(markers)]) plt.scatter( standard_embedding[marker_mask, 0], standard_embedding[marker_mask, 1], c=labels[marker_mask], s=20, cmap=\"Spectral\", marker=marker, alpha=0.8 ) Depending on the types of questions you want to answer with your data and assigned metadata, this may look different. To run a test on the provided data, try: python umap_HDBSCAN_basic.py ../test_input/embeddings_data test_metadata.tsv cluster_basic_with_metadata.png Enhanced HDBSCAN with UMAP \u00b6 Important note taken from HDBSCAN documentation: The next thing to be aware of is that when using UMAP for dimension reduction you will want to select different parameters than if you were using it for visualization. First of all we will want a larger n_neighbors value small values will focus more on very local structure and are more prone to producing fine grained cluster structure that may be more a result of patterns of noise in the data than actual clusters. In this case we will double it from the default 15 up to 30. Second it is beneficial to set min_dist to a very low value. Since we actually want to pack points together densely (density is what we want after all) a low value will help, as well as making cleaner separations between clusters. In this case we will simply set min_dist to be 0. Notice the difference between the basic HDBSCAN and the order of operations for the enhanced version: def plot_umap_hdbscan(embeddings, embedding_ids, output_file): # Perform UMAP dimensionality reduction standard_embedding = umap.UMAP(n_neighbors=3, min_dist=0.2, n_components=2, metric='euclidean', random_state=42).fit_transform(embeddings) #HDBSCAN enhanced. Adjust according to data clusterable_embedding = umap.UMAP(n_neighbors=6, min_dist=0.0, n_components=2, random_state=42).fit_transform(embeddings) #Adjust according to data labels = hdbscan.HDBSCAN(min_samples=2, min_cluster_size=3).fit_predict(clusterable_embedding) #New cluster labels clustered = (labels >= 0) Compare the output of basic and enhanced versions to better understand how your clusters shift depending on the parameters you use and how you implement HDBSCAN with UMAP. To run a test on the data provided you can try out: python umap_HDBSCAN_enhanced.py ../test_input/embeddings_data cluster_enhanced.png If you would like to save the embedding ID and cluster assigned to output you can always add this line in: plt.close() #End of plot #Labels indexed in same order as embedding_id (very simple way of saving output) df = pd.DataFrame({ 'Embedding_ID': embedding_ids, 'Cluster': labels }) #Write to output as a tab table df.to_csv('cluster_output.tsv', sep='\\t', index=False) Authors \u00b6 Contact info zschreib@udel.edu Acknowledgments \u00b6 Inspiration, code snippets, etc. ESM2 , UMAP","title":"ESM Embedding Tutorial"},{"location":"embedding/#generating-embeddings-and-visualizion-tutorial","text":"This tutorial provides a step-by-step guide for generating embeddings using ESM2 and visualizing them with UMAP.","title":"Generating Embeddings and Visualizion Tutorial"},{"location":"embedding/#description","text":"This page will demonstrate how to use the ESM2 model to generate fine-tuned embeddings trained on viral proteins on the Biomix cluster. These embeddings capture important features of the sequences that can be useful for various downstream tasks in bioinformatics. Once the embeddings are generated, the next step will be to utilize UMAP (Uniform Manifold Approximation and Projection) to reduce their dimensionality and create visualizations. UMAP is a widely used technique for visualizing high-dimensional data, allowing for better interpretation and analysis of the high-dimensional embedding data.","title":"Description"},{"location":"embedding/#getting-started","text":"","title":"Getting Started"},{"location":"embedding/#dependencies","text":"If you have a working environment and wish to add the basic requirements, you can manually install the following. It is highly recommended to use conda and create a prebuilt environment provided below. ESM2 required to generate embeddings using pre-trained models. UMAP required for embedding visualization. PyTorch for tensor computation utilizing GPU. CUDA-Toolkit required for tools to utilize GPU. Needs to be a version compatible with your graphics card. Python >= 3.8","title":"Dependencies"},{"location":"embedding/#installation","text":"Conda setup (recommended) Help Note: The same conda environment can be use for running embeddings and visualization with UMAP so long as all the dependencies are installed. #Clone templates and test data git clone https://github.com/zschreib/embedding-tutorial.git cd embedding-tutorial #Create conda environment with requirements conda env create -f environment.yml #Activation needed for UMAP visualization but not embedding generation if you follow the embedding template conda activate esm-umap","title":"Installation"},{"location":"embedding/#generating-embeddings-of-viral-fine-tuned-models-using-contrastive-learning","text":"","title":"Generating Embeddings of viral fine-tuned models using contrastive learning."},{"location":"embedding/#configuration","text":"If you are running the provided scripts on Biomix they are pre-configured to utilize viral fine-tuned models in the extract.py. If you wish to use the general ESM2 pre-trained models on all domains of life you need to clone the ESM2 repo and point the embedding_template.sh to that extract.py script along with the correct pre-trained datasets. See their documentation for more information. #Move to the embedding template cd embedding_slurm_template #Open the template with your favorite text editor and adjust the paths accordingly #Biomix configuration needed to utilize GPU node. Adjust --mem accordingly (50GB should cover the models and your data) #!/bin/bash #SBATCH --job-name=test #SBATCH --time=UNLIMITED #SBATCH --gres=gpu:1 #SBATCH --partition=gpu2 #SBATCH --account=gpu2 #SBATCH --qos gpu #SBATCH --mem 50GB # Tells the node to activate your conda env before running job source activate esm-umap # Define path variables do not change unless you want to run your own models EXTRACT_SCRIPT=\"/mnt/VEIL/tools/embeddings/models/extract.py\" MODEL_PATH=\"/mnt/VEIL/tools/embeddings/models/esm2_t36_3B_UR50D.pt\" #Path to input amino acid fasta file and output directory. List full path INPUT_FILE=\"/work/user/fasta_file_location.fa\" OUTPUT_DIR=\"/work/user/output/dir\" #Run command for the embeddings to generate mean-representation of the protein python $EXTRACT_SCRIPT $MODEL_PATH $INPUT_FILE $OUTPUT_DIR --repr_layers 36 --include mean Once configured the script can be sent to the slurm job scheduler using: sbatch embedding_template.sh Logs will be found in the embedding_slurm_template directory.","title":"Configuration"},{"location":"embedding/#visualization-embedding-output-using-umap-for-dimensionality-reduction","text":"","title":"Visualization embedding output using UMAP for dimensionality reduction."},{"location":"embedding/#general-use-of-umap","text":"Basic introduction of how to process your embedding output. cd embedding-tutorial/umap_template Usage: python umap_visualize.py <input_directory> <output_plot_file.png> #Note: Highly recommened to read through the UMAP documentation and get an idea of what each of these input parameters do. #Adjust according to how you want to represent your data. umap.UMAP(n_neighbors=3, min_dist=0.5, n_components=2, metric='euclidean').fit(embeddings) To run the UMAP script against the test data provided you can enter the following: python umap_visualize.py ../test_input/embeddings_data/ test_out.png Note: You may see some warnings if not on a GPU node but as long as there is a png image output they job as finished.","title":"General use of UMAP"},{"location":"embedding/#advanced-umap-use-with-metadata","text":"Customize your plots with auto generated color maps or defined custom colors through metadata files. cd embedding-tutorial/umap_color_template #The test_metadata.tsv will give a basic overview on how to structure a metadata file Query_ID signature ENA_MN103542_MN103542_1_12796_10265_26 RDKL ENA_PP514360_PP514360_1_8414_6123_12 RDKL ENA_PP534163_PP534163_1_69504_71861_103 RDKF ENA_PP579741_PP579741_1_77727_75163_114 RDKF ENA_PP582188_PP582188_1_34616_36967_50 RDKL ENA_PP554395_PP554395_1_25693_23567_24 ABCD Values here will either be auto assigned a color based on the 'signature' column or manually assigned by how you structure the umap_color_visualize.py file #Example of how to edit the map_color_visualize.py file to assign custom colors manually def custom_color_manual(metadata_df, column_name): # Predefined color table color_table = { \"RDKF\": '#ec4400', \"RDKL\": '#8c29b1', \"RDKY\": '#1b33e3', \"RDKH\": '#008856', # Add more entries as needed } #Note: ENA_PP554395_PP554395_1_25693_23567_24 ABCD and other embeddings present in your that do not have a mapping will default to gray #The manual and auto color generation will be saved here in the main function metadata_df['auto_color'] = metadata_df[column_name].map(auto_colors) metadata_df['manual_color'] = metadata_df[column_name].map(manual_colors) #You can use these in the plot_umap(embeddings, embedding_ids, metadata_df, output_path) #by going to the function and selecting the color map you want. #Auto def plot_umap(embeddings, embedding_ids, metadata, output_file): #maps your ids to color dictionary. id_to_color = dict(zip(metadata['Query_ID'], metadata['auto_color'])) #Manual def plot_umap(embeddings, embedding_ids, metadata, output_file): #maps your ids to color dictionary. id_to_color = dict(zip(metadata['Query_ID'], metadata['manual_color'])) Here is how you can run the example data to visualize output with color. python umap_color_visualize.py ../test_input/embeddings_data test_metadata.tsv signature manual_color.png Note: You may see some warnings if not on a GPU node but as long as there is a png image output they job as finished. These templates are in place to a basic understanding on how to color UMAP plots in relation to your data. Feel free to edit them however you want for future analysis.","title":"Advanced UMAP use with metadata."},{"location":"embedding/#using-hdbscan-to-cluster-embedding-plots","text":"An introduction to using HDBSCAN with generated embeddings on a UMAP plot. For more information please see HDBSCAN utilization with UMAP. To learn more about what's going on behind HDBSCAN, check out How it works","title":"Using HDBSCAN to Cluster Embedding Plots"},{"location":"embedding/#basic-hdbscan","text":"This performs HDBSCAN clustering directly on your UMAP-transformed embeddings without taking into account local structure. The UMAP transformation and HDBSCAN clustering happen here: def plot_umap_hdbscan(embeddings, embedding_ids, metadata, output_file): #Perform UMAP dimensionality reduction standard_embedding = umap.UMAP(n_neighbors=3, min_dist=0.2, n_components=2, metric='euclidean', random_state=42).fit_transform(embeddings) #Perform clustering with HDBSCAN labels = hdbscan.HDBSCAN(min_samples=2, min_cluster_size=3).fit_predict(embeddings) clustered = (labels >= 0) We can now plot the clustered and unclustered data here: #Plotting the UMAP results with HDBSCAN clusters plt.figure(figsize=(10, 7)) plt.scatter( standard_embedding[~clustered, 0], standard_embedding[~clustered, 1], color=\"gray\", s=20, alpha=0.5, label=\"Noise\", marker=\"1\" #tri_down for unclustered data ) #Shapes applied to clustered data only (can modify to all if needed) unique_markers = set(markers) for marker in unique_markers: #Shape to embedding id marker_mask = np.array([(m == marker) and clustered[i] for i, m in enumerate(markers)]) plt.scatter( standard_embedding[marker_mask, 0], standard_embedding[marker_mask, 1], c=labels[marker_mask], s=20, cmap=\"Spectral\", marker=marker, alpha=0.8 ) Depending on the types of questions you want to answer with your data and assigned metadata, this may look different. To run a test on the provided data, try: python umap_HDBSCAN_basic.py ../test_input/embeddings_data test_metadata.tsv cluster_basic_with_metadata.png","title":"Basic HDBSCAN"},{"location":"embedding/#enhanced-hdbscan-with-umap","text":"Important note taken from HDBSCAN documentation: The next thing to be aware of is that when using UMAP for dimension reduction you will want to select different parameters than if you were using it for visualization. First of all we will want a larger n_neighbors value small values will focus more on very local structure and are more prone to producing fine grained cluster structure that may be more a result of patterns of noise in the data than actual clusters. In this case we will double it from the default 15 up to 30. Second it is beneficial to set min_dist to a very low value. Since we actually want to pack points together densely (density is what we want after all) a low value will help, as well as making cleaner separations between clusters. In this case we will simply set min_dist to be 0. Notice the difference between the basic HDBSCAN and the order of operations for the enhanced version: def plot_umap_hdbscan(embeddings, embedding_ids, output_file): # Perform UMAP dimensionality reduction standard_embedding = umap.UMAP(n_neighbors=3, min_dist=0.2, n_components=2, metric='euclidean', random_state=42).fit_transform(embeddings) #HDBSCAN enhanced. Adjust according to data clusterable_embedding = umap.UMAP(n_neighbors=6, min_dist=0.0, n_components=2, random_state=42).fit_transform(embeddings) #Adjust according to data labels = hdbscan.HDBSCAN(min_samples=2, min_cluster_size=3).fit_predict(clusterable_embedding) #New cluster labels clustered = (labels >= 0) Compare the output of basic and enhanced versions to better understand how your clusters shift depending on the parameters you use and how you implement HDBSCAN with UMAP. To run a test on the data provided you can try out: python umap_HDBSCAN_enhanced.py ../test_input/embeddings_data cluster_enhanced.png If you would like to save the embedding ID and cluster assigned to output you can always add this line in: plt.close() #End of plot #Labels indexed in same order as embedding_id (very simple way of saving output) df = pd.DataFrame({ 'Embedding_ID': embedding_ids, 'Cluster': labels }) #Write to output as a tab table df.to_csv('cluster_output.tsv', sep='\\t', index=False)","title":"Enhanced HDBSCAN with UMAP"},{"location":"embedding/#authors","text":"Contact info zschreib@udel.edu","title":"Authors"},{"location":"embedding/#acknowledgments","text":"Inspiration, code snippets, etc. ESM2 , UMAP","title":"Acknowledgments"},{"location":"structure/","text":"Guide to generating and comparing 3D protein structures \u00b6 This tutorial provides a step by step guide for generating 3D structural predictions using the AlphaFold3 web interface and performing structural comparisons using the Foldseek and DALI web server. Prerequisites \u00b6 No coding knowledge is required. The only setup needed is to create an account on the AlphaFold3 web server: https://alphafoldserver.com/welcome . Note that this web interface is not ideal for analyses requiring large batches of 3D predictions (as you are limited to 30 jobs per day) or custom templates, and it enforces fixed parameters. For more advanced and customizable workflows, consider using the open-source version of AlphaFold3: https://github.com/google-deepmind/alphafold3 though this does require a computational background. AlphaFold3 already provides a detailed guide, so please read the official documentation here: AlphaFold3 Guide before starting to fully understand the web interface. Getting Started \u00b6 For this tutorial, I will demonstrate the output using two sequences. By following this workflow, you will confidently be able to report what they are. Sequence 1: Ga0531454_000088_17320_15773_17 MQTKNGLVPTLRLSFEMTDALASIEQEGLKINLDTLEEIERSYQQEMDDLEVRLKELAQDAVGDTPVNLASPDDRSMLLYSRRVTNKQEWAAIFNLGTERRGATVKPKMRRRMSRKEFNRNVGRLTEVVYKTRAERCTNCLGHGRTRVVKKDGTLGKATRVCRVCGGSGVVYHNTHEVAGFKLLPRTTYDLAAAGFRTDKDTLDERRDDLRGDGREFVESYVRYNALRTYLNTFVEGIKNNVDSKGFIHPEFMQCVTATGRLSSRNPNFQNMPRGSTFAIRKVVESRFSGGYILEGDYSQLEFRVAGFLAKDEQAYTDVKNSVDVHNYTASVIGCTRQEAKAHTFKPLYGGTSGTEDQKRYYAAFKDKYAGVTEWHEELQRQAVTKRVIALPSGREYAFPDARWTEYGTATNRTAICNYPVQGFATADLLPIALVSLHNVVKSAGIRSVICNTVHDSIVMDVHPDEKDTCIDLMKHAMLSLPFETMRRYGLAYDMPVGIELKMGKNWLDLHEVEL Sequence 2: Ga0531454_000088_18790_18007_20 YRVVTNDLDALIDEEVGDPDFPFEFELIREHLPGLDRGNLGILFARPEVGKTTFCSFLAASYVRQGFRVSYWANEEPAEKIMLRIAQSYFAVFTSEMRGPMREDFVRRYAEEIAPYLTIMDSVGTSIEELDDYAKLNKPDIIFADQLDKFRIGGEYNRGDERLKQTYVLAREIAKRNKCLVWAVSQASYEAHDRQFIDYSMLDNSRTGKAGEADIIIGIGKTGSSEVENTVRHICISKNKLNGYHGMINSQIDVRRGVYY 3D structruture predictions using Alphafold3 \u00b6 Submission \u00b6 Once logged in to Alphafold3, you should be directed to the default submission page. Paste the Sequence 1 residues into the input field and select Protein , as we are working with amino acid sequences. Set Copies to 1 since we are only interested in monomer predictions for this tutorial. Run Job \u00b6 You can optionally set a Job Name to help organize your submissions. If you want reproducible results, set a Seed value. The seed controls the random initialization of the model -- using the same seed with the same input will always return the same prediction. If left blank, the server will assign a random seed, which may yield slightly different outputs across runs. Click Confirm and submit job . The prediction process typically takes 5 to 10 minutes to complete but is largely dependent on the size of the protein. Below the sequence submission form is the Job History section. Once your job is finished, a checkmark will appear to the left of the job name. Click on the job name to view the 3D structure prediction. Results \u00b6 All results are displayed on this page. For more detailed explanations of each output, refer back to the guide mentioned at the beginning. The most important score here is the pTM (Predicted TM-score). Generally, a score above 0.5 suggests a predicted fold that may resemble one of the templates in the PDB. If you are seeing a lot of red and orange with a low pTM you may not want to use this structure. The ipTM (interface predicted TM-score) is currently blank because we are not modeling protein-protein interactions in this tutorial. Download \u00b6 Click the Download button at the top of the results page and unzip the directory to access the Crystallographic Information Files (.cif), which contain the atomic structure data. AlphaFold3 returns five sets of predictions, labeled model_0 through model_4, along with their corresponding confidence scores in the summary_confidences_0-4 files. In practice, model_0 often contains the best prediction, but it is a good idea to review all confidence scores to confirm. Follow up \u00b6 Repeat this process for sequence two. Once you have both model_0.cif for Sequence 1 and two you can move to the next step. Structural Comparison with Foldseek \u00b6 Foldseek is a fast and scalable tool for comparing protein 3D structures by aligning them using structural similarity, enabling high throughput searches across large structure databases. Submission \u00b6 After unzipping your AlphaFold3 output and selecting the best model (e.g., fold_sequence_1_test_model_0.cif), head over to the Foldseek Search Server to compare your predicted structure against a wide range of structural databases. Using the web interface limits some customization compared to running Foldseek locally, but again no coding experience is needed. For a deeper understanding of the Foldseek methods and advanced usage options, it is highly recommended to read through the official documentation: Foldseek GitHub Repository Foldseek Wiki Once on the Foldseek homepage, navigate to the Monomer Search tab (this should be the default view) and upload your protein.cif file of interest. Databases \u00b6 The image above shows the available subject databases and run options you can select. For phage (known and unknown), I typically stick with the parameters shown in the figure. I usually only select the databases highlighted there, but you can experiment with others depending on your research questions. Keep in mind that the more databases you select, the longer the job will take to run. Mode \u00b6 I recommend selecting TM-align as the search mode. For more information on the differences between available modes, consult the Foldseek GitHub documentation . Sensitivity \u00b6 Iterative searching is generally not needed if you are already identifying homologous hits to known sequences. It can increase runtime significantly but may help uncover distant homologs in more unknown sequences. Results \u00b6 Once your job is complete, the Results page will display a list of 1000 top hits for each database you selected, as well as an aggregated view under the ALL DATABASES tab, sorted by best scores. For this example, we will focus on the top hits in the BFVD database. Results are sorted by TM-align score , so you can choose the top ranking structure as the best representative. To explore more details, click on the Target URL to view the full entry on its dedicated results page. Depending on what you select, this will either redirect you to Foldseek BFVD or a Uniref results page. Download \u00b6 The top hit page is fairly self explanatory. In this example, we can see that our Sequence 1 test is similar to a DNA polymerase. To download the top hit representative structure, click the PDB button located above the structure viewer. To download the full top hit results table, navigate back to the Results page and use the dropdown menu to the left of the hit list and select the desired format for download. Follow up \u00b6 You now know how to generate a protein structure using AlphaFold3, perform a structural comparison with TM-align via Foldseek, identify top hits across multiple databases, explore annotations, and download a representative structure. However, if you are searching for unknowns and still receive low scores or no informative representatives, a different approach will be needed to further investigate the structure or function. Structural Comparison with DALI \u00b6 DALI (Distance matrix ALIgnment) compares protein structures based on intramolecular distance patterns to detect structural similarities, even among distantly related proteins. Submission \u00b6 If you are still interested in exploring your sequence of interest and did not find informative hits using Foldseek, you can try the DALI webserver . In this example, I search Sequence 1 against the Protein Data Bank (PDB) using PDB Search by uploading a .pdb file and providing a Job title and Email address to receive the results. Important: DALI does not accept .cif files, so you must convert your AlphaFold3 output to .pdb format before submitting. You can write your own script or use this online converter: .cif -> to -> .pdb converter Results \u00b6 You should receive an email with the results in about 5 to 10 minutes. Alternatively, the submission page may redirect you directly to the results once processing is complete if you have the tab open. A detailed explanation of the DALI output can be found in the following guide: DALI Tutorial 2022 (PDF) For that reason, I will not go into detail here about how to interpret the output. Whether through the page redirection or the email link, you will be taken to the DALI results page. From here, you can explore individual hits or download the full results table. For this tutorial, we will focus on the Matches against full PDB section to get a comprehensive view of structural similarities. The DALI results table summarizes structural alignments between your query and known protein structures. Key columns include: Z : Statistical significance of the alignment (higher = more confident match) RMSD : Root-mean-square deviation between aligned structures %ID : Percent sequence identity PDB : Link to the matched PDB entry Description : Functional annotation of the hit In this example, the top hits all align to DNA polymerase proteins, suggesting strong structural similarity with the query sequence. The top hit aligns with the 1kfd-A chain, showing a high Z-score and a moderately low RMSD , which suggests similar function but some degree of structural divergence in the fold. You can look up this complex on the RCSB PDB to view the full crystal structure along with other metadata: https://www.rcsb.org/structure/1KFD Follow up \u00b6 This section provides a way to search for more remote homology by using Z-score and RMSD values to assess fold similarity. Even when sequence identity is low, high Z-scores with reasonable RMSD values can indicate structural conservation. This can help refine your hypothesis about protein function. Follow-up analyses, such as structural alignments, allow you to precisely identify which regions of your unknown structure align with known proteins, offering deeper insight into potential roles and evolutionary relationships. Practice: Sequence 2 Analysis \u00b6 Try running this workflow with Sequence 2 to see if you can generate a confident structural prediction. Based on the Foldseek or DALI results, assess whether any functional or structural annotations can be confidently assigned. If you are curious whether Sequence 2 may physically interact with Sequence 1 , consider testing them together using AlphaFold3 Multimer , which is designed to predict protein-protein complexes. Authors \u00b6 Contributors names and contact info zschreib@udel.edu Acknowledgments \u00b6 The tutorial here utilizes tools from various sources: Abramson, J et al. Accurate structure prediction of biomolecular interactions with AlphaFold 3. Nature, 2024. van Kempen M, Kim S, Tumescheit C, Mirdita M, Lee J, Gilchrist CLM, Soding J, and Steinegger M. Fast and accurate protein structure search with Foldseek. Nature Biotechnology, 2023. Holm, Liisa. Dali server: structural unification of protein families. Nucleic acids research 50.W1, 2022. Sebastian Bittrich, Joan Segura, Jose M Duarte, Stephen K Burley, Yana Rose, RCSB protein Data Bank: exploring protein 3D similarities via comprehensive structural alignments. Bioinformatics, Volume 40, Issue 6, June 2024.","title":"3D protein structure Tutorial"},{"location":"structure/#guide-to-generating-and-comparing-3d-protein-structures","text":"This tutorial provides a step by step guide for generating 3D structural predictions using the AlphaFold3 web interface and performing structural comparisons using the Foldseek and DALI web server.","title":"Guide to generating and comparing 3D protein structures"},{"location":"structure/#prerequisites","text":"No coding knowledge is required. The only setup needed is to create an account on the AlphaFold3 web server: https://alphafoldserver.com/welcome . Note that this web interface is not ideal for analyses requiring large batches of 3D predictions (as you are limited to 30 jobs per day) or custom templates, and it enforces fixed parameters. For more advanced and customizable workflows, consider using the open-source version of AlphaFold3: https://github.com/google-deepmind/alphafold3 though this does require a computational background. AlphaFold3 already provides a detailed guide, so please read the official documentation here: AlphaFold3 Guide before starting to fully understand the web interface.","title":"Prerequisites"},{"location":"structure/#getting-started","text":"For this tutorial, I will demonstrate the output using two sequences. By following this workflow, you will confidently be able to report what they are. Sequence 1: Ga0531454_000088_17320_15773_17 MQTKNGLVPTLRLSFEMTDALASIEQEGLKINLDTLEEIERSYQQEMDDLEVRLKELAQDAVGDTPVNLASPDDRSMLLYSRRVTNKQEWAAIFNLGTERRGATVKPKMRRRMSRKEFNRNVGRLTEVVYKTRAERCTNCLGHGRTRVVKKDGTLGKATRVCRVCGGSGVVYHNTHEVAGFKLLPRTTYDLAAAGFRTDKDTLDERRDDLRGDGREFVESYVRYNALRTYLNTFVEGIKNNVDSKGFIHPEFMQCVTATGRLSSRNPNFQNMPRGSTFAIRKVVESRFSGGYILEGDYSQLEFRVAGFLAKDEQAYTDVKNSVDVHNYTASVIGCTRQEAKAHTFKPLYGGTSGTEDQKRYYAAFKDKYAGVTEWHEELQRQAVTKRVIALPSGREYAFPDARWTEYGTATNRTAICNYPVQGFATADLLPIALVSLHNVVKSAGIRSVICNTVHDSIVMDVHPDEKDTCIDLMKHAMLSLPFETMRRYGLAYDMPVGIELKMGKNWLDLHEVEL Sequence 2: Ga0531454_000088_18790_18007_20 YRVVTNDLDALIDEEVGDPDFPFEFELIREHLPGLDRGNLGILFARPEVGKTTFCSFLAASYVRQGFRVSYWANEEPAEKIMLRIAQSYFAVFTSEMRGPMREDFVRRYAEEIAPYLTIMDSVGTSIEELDDYAKLNKPDIIFADQLDKFRIGGEYNRGDERLKQTYVLAREIAKRNKCLVWAVSQASYEAHDRQFIDYSMLDNSRTGKAGEADIIIGIGKTGSSEVENTVRHICISKNKLNGYHGMINSQIDVRRGVYY","title":"Getting Started"},{"location":"structure/#3d-structruture-predictions-using-alphafold3","text":"","title":"3D structruture predictions using Alphafold3"},{"location":"structure/#submission","text":"Once logged in to Alphafold3, you should be directed to the default submission page. Paste the Sequence 1 residues into the input field and select Protein , as we are working with amino acid sequences. Set Copies to 1 since we are only interested in monomer predictions for this tutorial.","title":"Submission"},{"location":"structure/#run-job","text":"You can optionally set a Job Name to help organize your submissions. If you want reproducible results, set a Seed value. The seed controls the random initialization of the model -- using the same seed with the same input will always return the same prediction. If left blank, the server will assign a random seed, which may yield slightly different outputs across runs. Click Confirm and submit job . The prediction process typically takes 5 to 10 minutes to complete but is largely dependent on the size of the protein. Below the sequence submission form is the Job History section. Once your job is finished, a checkmark will appear to the left of the job name. Click on the job name to view the 3D structure prediction.","title":"Run Job"},{"location":"structure/#results","text":"All results are displayed on this page. For more detailed explanations of each output, refer back to the guide mentioned at the beginning. The most important score here is the pTM (Predicted TM-score). Generally, a score above 0.5 suggests a predicted fold that may resemble one of the templates in the PDB. If you are seeing a lot of red and orange with a low pTM you may not want to use this structure. The ipTM (interface predicted TM-score) is currently blank because we are not modeling protein-protein interactions in this tutorial.","title":"Results"},{"location":"structure/#download","text":"Click the Download button at the top of the results page and unzip the directory to access the Crystallographic Information Files (.cif), which contain the atomic structure data. AlphaFold3 returns five sets of predictions, labeled model_0 through model_4, along with their corresponding confidence scores in the summary_confidences_0-4 files. In practice, model_0 often contains the best prediction, but it is a good idea to review all confidence scores to confirm.","title":"Download"},{"location":"structure/#follow-up","text":"Repeat this process for sequence two. Once you have both model_0.cif for Sequence 1 and two you can move to the next step.","title":"Follow up"},{"location":"structure/#structural-comparison-with-foldseek","text":"Foldseek is a fast and scalable tool for comparing protein 3D structures by aligning them using structural similarity, enabling high throughput searches across large structure databases.","title":"Structural Comparison with Foldseek"},{"location":"structure/#submission_1","text":"After unzipping your AlphaFold3 output and selecting the best model (e.g., fold_sequence_1_test_model_0.cif), head over to the Foldseek Search Server to compare your predicted structure against a wide range of structural databases. Using the web interface limits some customization compared to running Foldseek locally, but again no coding experience is needed. For a deeper understanding of the Foldseek methods and advanced usage options, it is highly recommended to read through the official documentation: Foldseek GitHub Repository Foldseek Wiki Once on the Foldseek homepage, navigate to the Monomer Search tab (this should be the default view) and upload your protein.cif file of interest.","title":"Submission"},{"location":"structure/#databases","text":"The image above shows the available subject databases and run options you can select. For phage (known and unknown), I typically stick with the parameters shown in the figure. I usually only select the databases highlighted there, but you can experiment with others depending on your research questions. Keep in mind that the more databases you select, the longer the job will take to run.","title":"Databases"},{"location":"structure/#mode","text":"I recommend selecting TM-align as the search mode. For more information on the differences between available modes, consult the Foldseek GitHub documentation .","title":"Mode"},{"location":"structure/#sensitivity","text":"Iterative searching is generally not needed if you are already identifying homologous hits to known sequences. It can increase runtime significantly but may help uncover distant homologs in more unknown sequences.","title":"Sensitivity"},{"location":"structure/#results_1","text":"Once your job is complete, the Results page will display a list of 1000 top hits for each database you selected, as well as an aggregated view under the ALL DATABASES tab, sorted by best scores. For this example, we will focus on the top hits in the BFVD database. Results are sorted by TM-align score , so you can choose the top ranking structure as the best representative. To explore more details, click on the Target URL to view the full entry on its dedicated results page. Depending on what you select, this will either redirect you to Foldseek BFVD or a Uniref results page.","title":"Results"},{"location":"structure/#download_1","text":"The top hit page is fairly self explanatory. In this example, we can see that our Sequence 1 test is similar to a DNA polymerase. To download the top hit representative structure, click the PDB button located above the structure viewer. To download the full top hit results table, navigate back to the Results page and use the dropdown menu to the left of the hit list and select the desired format for download.","title":"Download"},{"location":"structure/#follow-up_1","text":"You now know how to generate a protein structure using AlphaFold3, perform a structural comparison with TM-align via Foldseek, identify top hits across multiple databases, explore annotations, and download a representative structure. However, if you are searching for unknowns and still receive low scores or no informative representatives, a different approach will be needed to further investigate the structure or function.","title":"Follow up"},{"location":"structure/#structural-comparison-with-dali","text":"DALI (Distance matrix ALIgnment) compares protein structures based on intramolecular distance patterns to detect structural similarities, even among distantly related proteins.","title":"Structural Comparison with DALI"},{"location":"structure/#submission_2","text":"If you are still interested in exploring your sequence of interest and did not find informative hits using Foldseek, you can try the DALI webserver . In this example, I search Sequence 1 against the Protein Data Bank (PDB) using PDB Search by uploading a .pdb file and providing a Job title and Email address to receive the results. Important: DALI does not accept .cif files, so you must convert your AlphaFold3 output to .pdb format before submitting. You can write your own script or use this online converter: .cif -> to -> .pdb converter","title":"Submission"},{"location":"structure/#results_2","text":"You should receive an email with the results in about 5 to 10 minutes. Alternatively, the submission page may redirect you directly to the results once processing is complete if you have the tab open. A detailed explanation of the DALI output can be found in the following guide: DALI Tutorial 2022 (PDF) For that reason, I will not go into detail here about how to interpret the output. Whether through the page redirection or the email link, you will be taken to the DALI results page. From here, you can explore individual hits or download the full results table. For this tutorial, we will focus on the Matches against full PDB section to get a comprehensive view of structural similarities. The DALI results table summarizes structural alignments between your query and known protein structures. Key columns include: Z : Statistical significance of the alignment (higher = more confident match) RMSD : Root-mean-square deviation between aligned structures %ID : Percent sequence identity PDB : Link to the matched PDB entry Description : Functional annotation of the hit In this example, the top hits all align to DNA polymerase proteins, suggesting strong structural similarity with the query sequence. The top hit aligns with the 1kfd-A chain, showing a high Z-score and a moderately low RMSD , which suggests similar function but some degree of structural divergence in the fold. You can look up this complex on the RCSB PDB to view the full crystal structure along with other metadata: https://www.rcsb.org/structure/1KFD","title":"Results"},{"location":"structure/#follow-up_2","text":"This section provides a way to search for more remote homology by using Z-score and RMSD values to assess fold similarity. Even when sequence identity is low, high Z-scores with reasonable RMSD values can indicate structural conservation. This can help refine your hypothesis about protein function. Follow-up analyses, such as structural alignments, allow you to precisely identify which regions of your unknown structure align with known proteins, offering deeper insight into potential roles and evolutionary relationships.","title":"Follow up"},{"location":"structure/#practice-sequence-2-analysis","text":"Try running this workflow with Sequence 2 to see if you can generate a confident structural prediction. Based on the Foldseek or DALI results, assess whether any functional or structural annotations can be confidently assigned. If you are curious whether Sequence 2 may physically interact with Sequence 1 , consider testing them together using AlphaFold3 Multimer , which is designed to predict protein-protein complexes.","title":"Practice: Sequence 2 Analysis"},{"location":"structure/#authors","text":"Contributors names and contact info zschreib@udel.edu","title":"Authors"},{"location":"structure/#acknowledgments","text":"The tutorial here utilizes tools from various sources: Abramson, J et al. Accurate structure prediction of biomolecular interactions with AlphaFold 3. Nature, 2024. van Kempen M, Kim S, Tumescheit C, Mirdita M, Lee J, Gilchrist CLM, Soding J, and Steinegger M. Fast and accurate protein structure search with Foldseek. Nature Biotechnology, 2023. Holm, Liisa. Dali server: structural unification of protein families. Nucleic acids research 50.W1, 2022. Sebastian Bittrich, Joan Segura, Jose M Duarte, Stephen K Burley, Yana Rose, RCSB protein Data Bank: exploring protein 3D similarities via comprehensive structural alignments. Bioinformatics, Volume 40, Issue 6, June 2024.","title":"Acknowledgments"}]}